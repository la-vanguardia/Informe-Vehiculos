\documentclass[]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-tabla]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}

\title{Procesamiento de imágenes utilizando Deep learning y Carla 
Simulator}
\author{}
\date{}

\begin{document}
    \maketitle

    \begin{abstract}
        
    \end{abstract}

    \section{Introducción}

    \section{Marco Teoríco}

    \subsection{Deep Learning}

    Las redes neuronal son muy utilizadas en el campo de la minería de datos, debido a 
    su gran versatilidad. Dentro de este mundo existen 2 grandes tipos de entrenamientos 
    para los supervisados que dada una entrada $X$ se conoce la salida deseada $Y$ y 
    otros casos los algoritmos no supervisados como los modelos de Q-learning o los mapas autoorganizados (SOM).
    En este proyecto se opto por un entrenamiento supervisado.

    Para el modelado de la red neuronal se utilizó un modelo llamado Pix2Pix \cite{Pix2Pix}.
    El cual pertime dada una imagen de entrada $X$ obtener una imagen de salida $Y$ haciendo uso 
    de una arquitecrua U-Net \cite{U-Net}. 
    
    Este modelo cuenta con 2 redes neuronales una denominada 
    el generador en cual recive la imagen $X$ y debe ser capaz de aprender a transformala en la imagen $\hat{Y}$, la cual es 
    una aproximación de la imagen $Y$.
    Y por otro lado el discriminador el cual debe tomar la imagen $\hat{Y}$ para lograr reconocer las partes de 
    esta que sean errorneas. La salida del discriminador debe ser una imagen resucida en tamaño que cuente con 
    un unico canal de color, siendo esta imagen una cuantificacion del error de la red generativa.

    Este problema desemboca en una pelea entre en generador ya que debe aprender a engañar al discriminador 
    y el discriminador que debe lograr siempre reconocer que la imagen $\hat{Y}$ es totalmente falsa, ya que es una 
    creación de la red generativa.

    \subsection{Preporcesado de los datos}

    Un paso fundamental para trabajar con algoritmos de imagenes es pasar del domininio $[0;255]$ a 
    un dominio mas acotado, para este trabajo se utilizo el domino de $[-1;1]$. De esta forma se logra 
    una mayor eficiencia computacional.

    Debido a la gran variedad de dimensiones de las imagenes es recomendable hacer un resize a dimensiones mas pequeñas 
    para disminuir el uso de RAM cuando son cargadas en memoria y el uso de GPU al realizar las convoluciones. En 
    este caso las imagenes de entrada y de salida son redimensionadas a $256x256$.

    \section{Desarrollo}

    \subsection{Obtención del dataset}

    Para obtener el dataset se colocaron una camara RGB y una camara de segmentación semántica
    \cite{CARLA-Sensors-Reference}, ubicadas en la misma posición. Se recolectaron los datos 
    cada 5 segundos. Las condiciones climaticas utilizadas fueron aletorias, lo que permite 
    obtener un dataset mucho mas variado.

    Para lograr un manejo autónomo del vehiculo se utilizó el autopilot \cite{CARLA-Documentation}. 
    Con la finalidad de aumentar la variedad de imagenes se utilizaron todos los mapas posibles y 
    se adicionaron otros vehiculos autónomos.

    \subsection{Entrenamiento de la red}

    Como fue mencinado en el marco teoríco el modelo implementado se denomina Pix2Pix \cite{Pix2Pix}.
    Se utilizó como entrada la imagen de la camara RGB y la salida será una imagen segmentada, para ello se utilizó
    el dataset que contava con casi 3000 imagenes. 

    Todas las imagenes fueron llevadas al domiminio $[-1;1]$ como es nombrado en la 

    El dataset fue dividido en 2 partes una utilizada para el entrenamiento, aproximadamente el $80 \% $ de las imagenes y 
    otra parte para el testing de la red utilizando el $20 \%$ restante.

    Luego de \textbf{N} iteraciones se presentan los resultados en la fig.\ref{fig:resultados}

    \begin{figure}[htb]
        \centering
        \caption{Imagenes obtenidas luego del entrenamiento}
        \label{fig:resultados}
    \end{figure}

    Las perdidas de la red generativa y del discriminador fueron recolectados para 
    lograr mostrar con mayor facilidad los avances del modelo (ver fig.\ref{fig:error-discriminador}-\ref{fig:error-generador})

    \begin{figure}[htb]
        \centering
        
        \caption{Error del discriminador en función de la iteración con el dataset de testing.}
        \label{fig:error-discriminador}
    \end{figure}

    \begin{figure}[htb]
        \centering
        
        \caption{Error del generador en función de la iteración con el dataset de testing.}
        \label{fig:error-generador}
    \end{figure}

    \section{Conclusiones}

    \bibliographystyle{IEEEannot}
    \bibliography{biblio}
\end{document}